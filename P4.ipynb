{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import pickle\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "from collections import deque   #use the collection to get the double-ended queue\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class Line():\n",
    "    \"\"\"class to receive the characteristics of each line detection\"\"\"\n",
    "    def __init__(self, frames_to_keep=5):\n",
    "        self.recent_nx = deque([], frames_to_keep)\n",
    "        self.recent_nfits = deque([], frames_to_keep)\n",
    "        self.recent_curvrad = deque([], frames_to_keep)\n",
    "        self.recent_x_pos = deque([], frames_to_keep)\n",
    "        self.last_found = False\n",
    "    \n",
    "    def found_fits(self):\n",
    "        return [f for f in self.recent_nfits if f is not None]\n",
    "    \n",
    "    def best_fit(self):\n",
    "        \"\"\"Returns the best fit according to the last n fits\"\"\"\n",
    "        found_fits = self.found_fits()\n",
    "        if not found_fits:\n",
    "            return None\n",
    "        else:\n",
    "            average_fit = np.mean(found_fits, axis=0)\n",
    "            return average_fit\n",
    "        \n",
    "    def best_x(self):\n",
    "        \"\"\"Returns the average non None x positions\"\"\"\n",
    "        found_x_pos = [x for x in self.recent_x_pos if x is not None]\n",
    "        return np.mean(found_x_pos)\n",
    "        \n",
    "    def line_valid(self, line_fit):\n",
    "        \"\"\"Decides whether the new appended line_fit is a valid line\"\"\"\n",
    "        curvrad = self.curvature_radius(line_fit)\n",
    "        xpos = self.calc_x_pos(line_fit)\n",
    "        best_x = self.best_x()\n",
    "        \n",
    "        # Regard curvature too low or large x difference as invalid\n",
    "        if curvrad < 350.0:\n",
    "            return False\n",
    "        if best_x and abs(xpos - best_x) > 70:\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "    def append_fit(self, line_fit):\n",
    "        \"\"\"Record new fitted line after sanity check\"\"\"\n",
    "        if not self.line_valid(line_fit):\n",
    "            if self.last_found:\n",
    "                self.recent_nfits.append(None)\n",
    "                self.last_found = False\n",
    "        else:\n",
    "            self.last_found = True\n",
    "            self.recent_nfits.append(line_fit)\n",
    "            self.recent_x_pos.append(self.calc_x_pos(line_fit))\n",
    "    \n",
    "    def curvature_radius(self, line_fit):\n",
    "        \"\"\"Calculate the curvature of fitted line\"\"\"\n",
    "        ym_per_pix = 30/720\n",
    "        xm_per_pix = 3.7/700\n",
    "        # refit line in world space\n",
    "        ploty = np.array([100, 200, 300, 400, 500])\n",
    "        # ploty = np.linspace(0, self.height-1, self.height)\n",
    "        plotx = line_fit[0]*ploty**2 + line_fit[1]*ploty + line_fit[2]\n",
    "        fit_cr = np.polyfit(ploty*ym_per_pix, plotx*xm_per_pix, 2)\n",
    "        \n",
    "        y_eval = 720*ym_per_pix\n",
    "        curvrad = ((1 + (2*fit_cr[0]*y_eval + fit_cr[1])**2)**1.5) / np.absolute(2*fit_cr[0])\n",
    "        return curvrad\n",
    "    \n",
    "    def current_curvature_radius(self):\n",
    "        \"\"\"Calculate the curvature radius using best fit\"\"\"\n",
    "        best_fit = self.best_fit()\n",
    "        return self.curvature_radius(best_fit)\n",
    "    \n",
    "    def calc_x_pos(self, line_fit):\n",
    "        \"\"\"Gets the bottom line pixel x coordinate\"\"\"\n",
    "        y_eval = 720\n",
    "        return np.int(line_fit[0]*y_eval**2 + line_fit[1]*y_eval + line_fit[2])\n",
    "class FineLane():\n",
    "    def __init__(self):\n",
    "        self.width = 1280\n",
    "        self.height = 720\n",
    "        self.left_lines = Line()\n",
    "        self.right_lines = Line()\n",
    "    \"\"\"fine the Laneline from car camera image\"\"\"\n",
    "    def calibrate_camera(self,force=False):\n",
    "        \"\"\"load the file\"\"\"\n",
    "        chessboard_images='./camera_cal/*.jpg'\n",
    "        \"\"\"save the file for reusing\"\"\"\n",
    "        dis_matrix_file='distort_mtx.p'\n",
    "        \n",
    "        if os.path.isfile(dis_matrix_file) and not force:\n",
    "            # load camera distortion matrix if already exists\n",
    "            dist_pickle = pickle.load(open(dis_matrix_file, 'rb'))\n",
    "            self.camera = {\n",
    "                'mtx': dist_pickle['mtx'],\n",
    "                'dist': dist_pickle['dist'],\n",
    "            }\n",
    "        else:\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "          # Start calibrating camera\n",
    "            # prepare object points\n",
    "            nx, ny = 9, 5\n",
    "            objp = np.zeros((nx*ny, 3), np.float32)\n",
    "            objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "            objpoints = []  # 3D coord in real world\n",
    "            imgpoints = []  # 2D coord in image plane\n",
    "\n",
    "            calibration_img_paths = glob.glob(chessboard_images)\n",
    "            # use tqdm to display progress bar\n",
    "            for img_path in tqdm(calibration_img_paths):\n",
    "                img = cv2.imread(img_path)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "                if ret == True:\n",
    "                    objpoints.append(objp)\n",
    "                    imgpoints.append(corners)\n",
    "\n",
    "            ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "                objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "            # Save the camera calibration result for later use\n",
    "            self.camera = {\n",
    "                'mtx': mtx,\n",
    "                'dist': dist,\n",
    "            }\n",
    "            # Save camera matrix to avoid recalibrating every time\n",
    "            # run with force=True to force recalibrate\n",
    "            pickle.dump(self.camera, open(dis_matrix_file, 'wb'))\n",
    "    def undistort(self,img):\n",
    "        \"\"\"Undistort image using camera matrix\"\"\"\n",
    "        assert 'mtx' in self.camera\n",
    "        assert 'dist' in self.camera\n",
    "        mtx = self.camera['mtx']\n",
    "        dist = self.camera['dist']\n",
    "        undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        return undist\n",
    "    def get_bird_eye_transform_matrix(self,reverse=False):\n",
    "        tls = (563, 470)  # top left source point\n",
    "        bls = (220, 700)  # bottom left source point\n",
    "        tld = (300, 300)  # top left destination \n",
    "        bld = (300, 720)  # bottom left destination\n",
    "        \n",
    "        src = np.float32([\n",
    "            [tls[0], tls[1]],\n",
    "            [self.width-tls[0], tls[1]],\n",
    "            [self.width-bls[0], bls[1]],\n",
    "            [bls[0], bls[1]]\n",
    "        ])\n",
    "\n",
    "        dst = np.float32([\n",
    "            [tld[0], tld[1]],\n",
    "            [self.width-tld[0], tld[1]],\n",
    "            [self.width-tld[0], bld[1]],\n",
    "            [bld[0], bld[1]],\n",
    "        ])\n",
    "        \n",
    "        if reverse:\n",
    "            transform_mtx = cv2.getPerspectiveTransform(dst, src)\n",
    "        else:\n",
    "            transform_mtx = cv2.getPerspectiveTransform(src, dst)\n",
    "        return transform_mtx\n",
    "    def bird_eye_transform(self,img,reverse=False):\n",
    "        \"\"\"Change the car camera image into bird eyes view\"\"\"\n",
    "        transform_mtx = self.get_bird_eye_transform_matrix(reverse=reverse)\n",
    "        shape = (self.width, self.height)\n",
    "        warped = cv2.warpPerspective(\n",
    "            img, transform_mtx, shape, flags=cv2.INTER_LINEAR)\n",
    "        return warped\n",
    "    def s_magnitude(self, img, s_thresh=(175, 255)):\n",
    "        \"\"\"\"for the s-channel\"\"\"\n",
    "        hls=cv2.cvtColor(img,cv2.COLOR_BGR2HLS)\n",
    "        s_channel = hls[:,:,2]\n",
    "        magnitude_binary = np.zeros_like(s_channel)\n",
    "        magnitude_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "        return magnitude_binary\n",
    "    def l_direction(self,img, sobel_kernel=5, m_thresh=(10, 255),d_thresh=(0.0, 0.75)):\n",
    "        \"\"\"find the L channel in HLS color\"\"\"\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "        l_channel = hls[:,:,1]\n",
    "         # 2) Take the gradient in x and y separately\n",
    "        sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        sobely = cv2.Sobel(l_channel, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        # 3) Take the absolute value of the x and y gradients\n",
    "        abs_sobelx=np.abs(sobelx)\n",
    "        abs_sobely=np.abs(sobely)\n",
    "        #Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "        grad=np.arctan2(abs_sobely, abs_sobelx)\n",
    "        # 4) Calculate the magnitude \n",
    "        mag=np.sqrt(sobelx**2+sobely**2)\n",
    "        # 5) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "        scale_factor = np.max(mag)/255\n",
    "        gradmag = (mag/scale_factor).astype(np.uint8) \n",
    "        #get the direction\n",
    "        binary_output=np.zeros_like(grad)\n",
    "        binary_output[\n",
    "            (grad >= d_thresh[0])&(grad <= d_thresh[1])&\n",
    "            (gradmag >= m_thresh[0])&(gradmag <= m_thresh[1])] = 1\n",
    "        return binary_output\n",
    "    def combined_thresholding(self, img):\n",
    "        \"\"\"Returns the combined result of all thresholdings\"\"\"\n",
    "        s_mag = self.s_magnitude(img)\n",
    "        l_dir = self.l_direction(img)\n",
    "        combined_binary = np.zeros_like(img[:,:,1])\n",
    "        combined_binary[(s_mag == 1) | (l_dir == 1)] = 1\n",
    "        return combined_binary \n",
    "    def histogram_find_lines(self,binary_warped, visualize=False):\n",
    "        \"\"\"get the formulate for the line\"\"\"\n",
    "        width, height = self.width, self.height\n",
    "        nwindows = 9\n",
    "        window_height = np.int(height/nwindows)\n",
    "        \n",
    "        histogram = np.sum(binary_warped[int(height/2):,:], axis=0)\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(width/2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        # Set the width of the windows +/- margin\n",
    "        margin = 100\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "        windows=[]\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "            win_y_high = binary_warped.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "            # Set the windows on the visualization image (draw later)\n",
    "            windows.append((win_xleft_low,win_y_low,win_xleft_high,win_y_high))\n",
    "            windows.append((win_xright_low,win_y_low,win_xright_high,win_y_high))\n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        \n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        \n",
    "        out_img=None\n",
    "        if visualize:\n",
    "            # color left/right lines\n",
    "            out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "            out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "            out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "            # draw window\n",
    "            for rect in windows:\n",
    "                tlx, tly, brx, bry = rect\n",
    "                cv2.rectangle(out_img, (tlx, tly), (brx, bry), (0, 255, 0), 2)\n",
    "                \n",
    "        \n",
    "        return left_fit, right_fit, out_img\n",
    "    \n",
    "    \n",
    "    def convolution_find_lines(self, binary_warped, left_fit, right_fit, visualize=False):\n",
    "        \"\"\"Find line around known previous lines\"\"\"\n",
    "        window_width = 50\n",
    "        hww = 25  # half window width\n",
    "        n_windows = 9\n",
    "        window_height = self.height/n_windows\n",
    "        window_centroids = []\n",
    "        margin = 100  # How much to slide left/right for searching\n",
    "        window = np.ones(window_width)\n",
    "        offset = np.int((window_width + margin)/2)\n",
    "\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "        \n",
    "        for level in range(n_windows):\n",
    "            y_min = np.int(level*window_height)\n",
    "            y_max = np.int(y_min + window_height)\n",
    "            layer = binary_warped[y_min:y_max,:]\n",
    "            image_layer = np.sum(layer, axis=0)\n",
    "            conv_signal = np.convolve(window, image_layer)\n",
    "            \n",
    "            y_eval = (y_min + y_max)/2\n",
    "            l_base = np.int(left_fit[0]*y_eval**2 + left_fit[1]*y_eval + left_fit[2])\n",
    "            l_base = max(0, min(self.width, l_base))\n",
    "            l_center = np.argmax(\n",
    "                conv_signal[max(0, l_base-offset): min(self.width,l_base+offset)]) + l_base - offset - hww\n",
    "            r_base = np.int(right_fit[0]*y_eval**2 + right_fit[1]*y_eval + right_fit[2])\n",
    "            r_base = max(0, min(self.width, r_base))\n",
    "            r_center = np.argmax(\n",
    "                conv_signal[max(0, r_base-offset): min(self.width, r_base+offset)]) + r_base - offset - hww\n",
    "            window_centroids.append((l_center, r_center))\n",
    "            good_left_inds = (\n",
    "                (nonzeroy >= y_min) & (nonzeroy <= y_max) & \n",
    "                (nonzerox >= (l_center-hww)) & (nonzerox <= (l_center+hww))).nonzero()[0]\n",
    "            good_right_inds = (\n",
    "                (nonzeroy >= y_min) & (nonzeroy <= y_max) &\n",
    "                (nonzerox >= (r_center-hww)) & (nonzerox <= (r_center+hww))).nonzero()[0]\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        \n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        \n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds]\n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        \n",
    "        out_img = None\n",
    "        if visualize:\n",
    "            # color left/right lines\n",
    "            out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "            out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "            out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "            \n",
    "            for level, (l_center, r_center) in enumerate(window_centroids):\n",
    "                tlx, tly, brx, bry = l_center-hww ,level*80, l_center+hww, (level+1)*80 \n",
    "                cv2.rectangle(out_img, (tlx, tly), (brx, bry), (0, 255, 0), 2)\n",
    "\n",
    "                tlx, tly, brx, bry = r_center-hww ,level*80, r_center+hww, (level+1)*80 \n",
    "                cv2.rectangle(out_img, (tlx, tly), (brx, bry), (0, 255, 0), 2)\n",
    "                \n",
    "                \n",
    "        return left_fit, right_fit, out_img\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def find_lines(self, img):\n",
    "        Find lane line\n",
    "        prev_left_fit = self.left_lines.best_fit()\n",
    "        prev_right_fit = self.right_lines.best_fit()\n",
    "        if prev_left_fit is None or prev_right_fit is None:\n",
    "            naive_left_fit, naive_right_fit, _ = self.histogram_find_lines(img)\n",
    "         #   prev_left_fit = naive_left_fit if prev_left_fit is None else prev_left_fit\n",
    "         #   prev_right_fit = naive_right_fit if prev_right_fit is None else prev_right_fit\n",
    "        \n",
    "        #new_left_fit, new_right_fit, _ = self.convolution_find_lines(img, prev_left_fit, prev_right_fit)\n",
    "        self.left_lines.append_fit(naive_left_fit)\n",
    "        self.right_lines.append_fit(naive_right_fit)\n",
    "        avg_left_fit = self.left_lines.best_fit()\n",
    "        avg_right_fit = self.right_lines.best_fit()\n",
    "            #if avg_left_fit is not None or avg_right_fit is not None:\n",
    "        #assert avg_right_fit is not None\n",
    "        return avg_left_fit, avg_right_fit\n",
    "        \n",
    "    \"\"\"\n",
    "    def find_lines(self, img):\n",
    "        \"\"\"Find lane line\"\"\"\n",
    "        prev_left_fit = self.left_lines.best_fit()\n",
    "        prev_right_fit = self.right_lines.best_fit()\n",
    "        if prev_left_fit is None or prev_right_fit is None:\n",
    "            naive_left_fit, naive_right_fit, _ = self.histogram_find_lines(img)\n",
    "            prev_left_fit = naive_left_fit if prev_left_fit is None else prev_left_fit\n",
    "            prev_right_fit = naive_right_fit if prev_right_fit is None else prev_right_fit\n",
    "        \n",
    "        new_left_fit, new_right_fit, _ = self.convolution_find_lines(img, prev_left_fit, prev_right_fit)\n",
    "        \n",
    "        self.left_lines.append_fit(new_left_fit)\n",
    "        self.right_lines.append_fit(new_right_fit)\n",
    "        avg_left_fit = self.left_lines.best_fit()\n",
    "        avg_right_fit = self.right_lines.best_fit()\n",
    "            #if avg_left_fit is not None or avg_right_fit is not None:\n",
    "        assert avg_left_fit is not None\n",
    "        assert avg_right_fit is not None\n",
    "        return avg_left_fit, avg_right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-9c5313cbb26c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./test_images/test1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mrgb_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-9c5313cbb26c>\u001b[0m in \u001b[0;36mimg_pipeline\u001b[0;34m(img, visualize)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mwarped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbird_eye_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcombined_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined_thresholding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mleft_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-2bde90be9ccf>\u001b[0m in \u001b[0;36mfind_lines\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mavg_right_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;31m#if avg_left_fit is not None or avg_right_fit is not None:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mavg_left_fit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mavg_right_fit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mavg_left_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_right_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Defind and test image pipeline\n",
    "# First make sure we initiate and calibrate the LandFinder class\n",
    "lf = FineLane()\n",
    "lf.calibrate_camera()\n",
    "\n",
    "def img_pipeline(img, visualize=False):\n",
    "    undist = lf.undistort(img)\n",
    "    warped = lf.bird_eye_transform(undist)\n",
    "    combined_binary = lf.combined_thresholding(warped)\n",
    "    left_fit, right_fit = lf.find_lines(combined_binary)\n",
    "    result = np.dstack((combined_binary, combined_binary, combined_binary))*255\n",
    "\n",
    "    ploty = np.linspace(0, lf.height-1, lf.height)\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    cp = np.zeros_like(result)\n",
    "    cv2.fillPoly(cp, np.int_([pts]), (0,255, 0))\n",
    "    road = lf.bird_eye_transform(cp, reverse=True)\n",
    "    result = cv2.addWeighted(undist, 1.0, road, 0.3, 0)\n",
    "\n",
    "    # Calculate curvature radius of both lines and average them\n",
    "    left_rad = lf.left_lines.current_curvature_radius()\n",
    "    right_rad = lf.right_lines.current_curvature_radius()\n",
    "    mean_rad = (left_rad + right_rad)/2\n",
    "    \n",
    "    # Calculate center of the road to the center of the image\n",
    "    left_x = lf.left_lines.best_x()   # left line bottom pixel x position\n",
    "    right_x = lf.right_lines.best_x() # right line bottom pixel x position\n",
    "    offset_x = (1280/2) - (left_x + right_x)/2\n",
    "    offset_direction = \"right\" if offset_x > 0 else \"left\"\n",
    "    offset_x_meter = offset_x * 3.7/700\n",
    "    \n",
    "    # write radius and offset onto image\n",
    "    result = cv2.putText(\n",
    "        result, 'Radius of Curvature = %.0f' % (mean_rad), \n",
    "        (50, 70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3)\n",
    "    result = cv2.putText(\n",
    "        result, 'Vehicle is %.2f m %s of center' % (abs(offset_x_meter), offset_direction), \n",
    "        (50, 140), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3)\n",
    "\n",
    "    \n",
    "    return result\n",
    "\n",
    "img = cv2.imread('./test_images/test1.jpg')\n",
    "result = img_pipeline(img, visualize=True)\n",
    "rgb_result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb_result)\n",
    "cv2.imwrite('./output_images/curvature_radius.jpg', result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# run image pipeline with video\n",
    "outfile = 'results.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(img_pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(outfile, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (720, 1280)\n",
    "lf = FineLane()\n",
    "lf.calibrate_camera()\n",
    "img = cv2.imread('./camera_cal/calibration1.jpg')\n",
    "rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "undist = lf.undistort(img)\n",
    "# visualize and save undistorted image\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1.imshow(rgb)\n",
    "ax1.set_title('Original Image', fontsize=15)\n",
    "ax2.imshow(undist)\n",
    "ax2.set_title('Undistorted Image', fontsize=15)\n",
    "plt.imsave('./output_images/chessboard_original.jpg', rgb)\n",
    "plt.imsave('./output_images/chessboard_undistort.jpg', undist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=[\n",
    "    \n",
    "    './test_images/straight_lines1.jpg',\n",
    "    './test_images/test1.jpg'\n",
    "    \n",
    "]\n",
    "f, axarr = plt.subplots(len(test_images), 2, figsize=(20, 5*len(test_images)))\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    img = cv2.imread(img_path)\n",
    "    undist = lf.undistort(img)\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    warped = lf.bird_eye_transform(rgb)\n",
    "    \n",
    "    \n",
    "    axarr[idx][0].imshow(rgb)\n",
    "    axarr[idx][1].imshow(warped)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thershold method\n",
    "test_images=[\n",
    "   './test_images/straight_lines1.jpg',\n",
    "    './test_images/straight_lines2.jpg',\n",
    "    './test_images/test1.jpg',\n",
    "    './test_images/test2.jpg',\n",
    "    './test_images/test3.jpg',\n",
    "    './test_images/test4.jpg',\n",
    "    './test_images/test5.jpg',\n",
    "    './test_images/test6.jpg',\n",
    "    \n",
    "]\n",
    "f, axarr = plt.subplots(len(test_images), 2, figsize=(20, 5*len(test_images)))\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    img = cv2.imread(img_path)\n",
    "    undist = lf.undistort(img)\n",
    "    warped = lf.bird_eye_transform(undist)\n",
    "    s_mag = lf.s_magnitude(warped)\n",
    "    l_dir = lf.l_direction(warped)\n",
    "    \n",
    "    color_stack = np.dstack(( np.zeros_like(s_mag), s_mag, l_dir))\n",
    "    combined_binary = lf.combined_thresholding(warped)\n",
    "        \n",
    "    # plot the result images\n",
    "    axarr[idx, 0].imshow(color_stack)\n",
    "    axarr[idx, 0].set_title('color_stack', fontsize=15)\n",
    "\n",
    "    axarr[idx, 1].imshow(combined_binary, cmap='gray')\n",
    "    axarr[idx, 1].set_title('combined_binary', fontsize=15)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the line and get the line \n",
    "test_images=[\n",
    "   './test_images/straight_lines1.jpg',\n",
    "    './test_images/straight_lines2.jpg',\n",
    "    './test_images/test1.jpg',\n",
    "    './test_images/test2.jpg',\n",
    "    './test_images/test3.jpg',\n",
    "    './test_images/test4.jpg',\n",
    "    './test_images/test5.jpg',\n",
    "    './test_images/test6.jpg',   \n",
    "]\n",
    "f, axarr = plt.subplots(len(test_images), 2, figsize=(20, 5*len(test_images)))\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    img = cv2.imread(img_path)\n",
    "    undist = lf.undistort(img)\n",
    "    warped = lf.bird_eye_transform(undist)\n",
    "    combined_binary = lf.combined_thresholding(warped)\n",
    "    copy_combined_binary = np.copy(combined_binary)\n",
    "    \n",
    "    hist_left_fit, hist_right_fit, visualize_hist_search = lf.histogram_find_lines(\n",
    "        copy_combined_binary, visualize=True)\n",
    "    #left_fit, right_fit, visualize_conv_search = lf.convolution_find_lines(\n",
    "    #    combined_binary, hist_left_fit, hist_right_fit, visualize=True)\n",
    "    rgb_warped = cv2.cvtColor(warped, cv2.COLOR_BGR2RGB)\n",
    "    axarr[idx][0].imshow(rgb_warped)\n",
    "    \n",
    "    # plot naive_find_lines line\n",
    "    ploty = np.linspace(0, lf.height-1, lf.height)\n",
    "    hist_left_fitx = hist_left_fit[0]*ploty**2 + hist_left_fit[1]*ploty + hist_left_fit[2]\n",
    "    hist_right_fitx = hist_right_fit[0]*ploty**2 + hist_right_fit[1]*ploty + hist_right_fit[2]\n",
    "    \n",
    "    axarr[idx][1].imshow(visualize_hist_search, cmap='gray')\n",
    "    axarr[idx][1].plot(hist_left_fitx, ploty, color='yellow')\n",
    "    axarr[idx][1].plot(hist_right_fitx, ploty, color='yellow')\n",
    "    axarr[idx][1].set_xlim([0, 1280])\n",
    "    axarr[idx][1].set_ylim([720, 0])\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
